---
title: "Generalised Linear Models"
author: "Thinh"
date: "7/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
theme_set(theme_light())
```

# Import data 

```{r}
acs <- read.table("http://jaredlander.com/data/acs_ny.csv", sep = ",", header = TRUE, stringsAsFactors = FALSE)
```

# Whether a househould has an income greater than $150,000
```{r}
acs$Income <- with(acs, FamilyIncome >= 150000)

ggplot(acs, aes(FamilyIncome)) + 
  geom_density(fill = "grey", colour = "grey") + 
  geom_vline(xintercept = 150000) +
  scale_x_continuous(labels = scales::dollar, limits = c(0, 1000000))
  
```

# Running logistic regression 


```{r}
income1 <- glm(Income ~ HouseCosts + NumWorkers + OwnRent + NumBedrooms + FamilyType,
               data = acs,
               family = binomial(link = "logit"))

summary(income1)
```

* The coefficients represent the effect of the predictors on the response and the standard errors are the uncertainty in the estimation of the coefficients. The t value (t-statistic) and p-value for the coefficients are numerical measures of statistical significance, though these should be viewed with caution as most modern data scientists do not like to look at the statistical significance of individual coefficients.

* The model p-value and F-statistic are measures of its goodness of fit. The degrees of freedom for a regression are calculated as the number of observations minus the number of coefficients.

```{r}
coefplot::coefplot(income1)
```

* each coefficient is plotted as a point with a thick line representing the one standard error confidence interval and a thin line representing the two standard error confidence interval. There is a vertical line indicating 0. In general, a good rule of thumb is that if the two standard error confidence interval does not contain 0, it is statistically significant

